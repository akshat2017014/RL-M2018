{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necessary header files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_evaluation(v_s,pi_s,theeta,gamma):\n",
    "    counter=0\n",
    "    while(True):\n",
    "        delta=0;\n",
    "        for i in range(4):\n",
    "            for j in range(4):\n",
    "                v=v_s[i,j]\n",
    "                new_v_s=0\n",
    "                if(i==0  and j==0):\n",
    "                    new_v_s+=0\n",
    "                elif(i==3 and j==3):\n",
    "                    new_v_s+=0\n",
    "                else:\n",
    "                    if(pi_s[i,j]==0):\n",
    "                        if(i-1>=0):\n",
    "                            new_v_s+=1*(-1+gamma*v_s[i-1,j])\n",
    "                        else:\n",
    "                            new_v_s+=1*(-1+gamma*v_s[i,j])\n",
    "                    elif(pi_s[i,j]==1):\n",
    "                        if(j+1<=3):\n",
    "                            new_v_s+=1*(-1+gamma*v_s[i,j+1])\n",
    "                        else:\n",
    "                            new_v_s+=1*(-1+gamma*v_s[i,j])\n",
    "                    elif(pi_s[i,j]==2):\n",
    "                        if(i+1<=3):\n",
    "                            new_v_s+=1*(-1+gamma*v_s[i+1,j])\n",
    "                        else:\n",
    "                            new_v_s+=1*(-1+gamma*v_s[i,j])\n",
    "                    elif(pi_s[i,j]==3):\n",
    "                        if(j-1>=0):\n",
    "                            new_v_s+=1*(-1+gamma*v_s[i,j-1])\n",
    "                        else:\n",
    "                            new_v_s+=1*(-1+gamma*v_s[i,j])\n",
    "                v_s[i,j]=new_v_s\n",
    "                delta=max(delta,abs(v-new_v_s))\n",
    "        if(delta<theeta):\n",
    "            break\n",
    "\n",
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_improvement(v_s,pi_s,gamma):\n",
    "    policy_stable=True\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            old_action=pi_s[i,j]\n",
    "            new_policy=pi_s[i,j]\n",
    "            max=-9999999\n",
    "            if(((i!=0 or j!=0) and  (i!=3 or j!=3))):\n",
    "                temp=0\n",
    "                if(i-1>=0):\n",
    "                    temp=1*(-1+gamma*v_s[i-1,j])\n",
    "                else:\n",
    "                    temp=1*(-1+gamma*v_s[i,j])\n",
    "                if(temp>max):\n",
    "                    max=temp\n",
    "                    new_policy=0\n",
    "                if(j+1<=3):\n",
    "                    temp=1*(-1+gamma*v_s[i,j+1])\n",
    "                else:\n",
    "                    temp=1*(-1+gamma*v_s[i,j])\n",
    "                if(temp>max):\n",
    "                    max=temp\n",
    "                    new_policy=1       \n",
    "                if(i+1<=3):\n",
    "                    temp=1*(-1+gamma*v_s[i+1,j])\n",
    "                else:\n",
    "                    temp=1*(-1+gamma*v_s[i,j])\n",
    "                if(temp>max):\n",
    "                    max=temp\n",
    "                    new_policy=2\n",
    "                if(j-1>=0):\n",
    "                    temp=1*(-1+gamma*v_s[i,j-1])\n",
    "                else:\n",
    "                    temp=1*(-1+gamma*v_s[i,j])\n",
    "                if(temp>max):\n",
    "                    max=temp\n",
    "                    new_policy=3\n",
    "            pi_s[i,j]=new_policy\n",
    "            if(old_action!=new_policy):\n",
    "                policy_stable=False\n",
    "    return policy_stable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_iteration():\n",
    "    print(\"----policy_iteartion----\")\n",
    "    v_s=np.zeros([4,4])\n",
    "    pi_s=np.zeros([4,4]);\n",
    "    theeta=0.000000001\n",
    "    gamma=0.9\n",
    "    policy_evaluation(v_s,pi_s,theeta,gamma)\n",
    "    counter=1;\n",
    "    while(policy_improvement(v_s,pi_s,gamma)==False):\n",
    "        print(\"iteration No.\",counter,\":\")\n",
    "        print(\"Value function:\")\n",
    "        print(v_s)\n",
    "        print(\"Policy Selected:\")\n",
    "        print(pi_s)\n",
    "        print()\n",
    "        counter+=1\n",
    "        policy_evaluation(v_s,pi_s,theeta,gamma)\n",
    "    print(\"iteration No.\",counter,\":\")\n",
    "    print(\"Value function:\")\n",
    "    print(v_s)\n",
    "    print(\"Policy Selected:\")\n",
    "    print(pi_s)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " v_s[i,j] and pi_s[i,j] represents expected reward and policy repectively, corresponding to each state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "policies:\n",
    "0->up\n",
    "1->right\n",
    "2->down\n",
    "3->left"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The order in which we are checking for optimal policy in policy improvement is same, thus in case of two policies having same expected value convergence is always possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deterministic_policy(v_s,pi_s,gamma):\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            max=-9999999\n",
    "            if(((i!=0 or j!=0) and  (i!=3 or j!=3))):\n",
    "                temp=0\n",
    "                if(i-1>=0):\n",
    "                    temp=1*(-1+gamma*v_s[i-1,j])\n",
    "                else:\n",
    "                    temp=1*(-1+gamma*v_s[i,j])\n",
    "                if(temp>max):\n",
    "                    max=temp\n",
    "                    new_policy=0\n",
    "                if(j+1<=3):\n",
    "                    temp=1*(-1+gamma*v_s[i,j+1])\n",
    "                else:\n",
    "                    temp=1*(-1+gamma*v_s[i,j])\n",
    "                if(temp>max):\n",
    "                    max=temp\n",
    "                    new_policy=1       \n",
    "                if(i+1<=3):\n",
    "                    temp=1*(-1+gamma*v_s[i+1,j])\n",
    "                else:\n",
    "                    temp=1*(-1+gamma*v_s[i,j])\n",
    "                if(temp>max):\n",
    "                    max=temp\n",
    "                    new_policy=2\n",
    "                if(j-1>=0):\n",
    "                    temp=1*(-1+gamma*v_s[i,j-1])\n",
    "                else:\n",
    "                    temp=1*(-1+gamma*v_s[i,j])\n",
    "                if(temp>max):\n",
    "                    max=temp\n",
    "                    new_policy=3\n",
    "                pi_s[i,j]=new_policy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_iteration():\n",
    "    v_s=np.zeros([4,4])\n",
    "    pi_s=np.zeros([4,4]);\n",
    "    theeta=0.00000001\n",
    "    gamma=0.9\n",
    "    while(True):\n",
    "        delta=0;\n",
    "        for i in range(4):\n",
    "            for j in range(4):\n",
    "                v=v_s[i,j]\n",
    "                new_v=v_s[i,j]\n",
    "                max1=-9999999\n",
    "                if(((i!=0 or j!=0) and  (i!=3 or j!=3))):\n",
    "                    temp=0\n",
    "                    if(i-1>=0):\n",
    "                        temp=1*(-1+gamma*v_s[i-1,j])\n",
    "                    else:\n",
    "                        temp=1*(-1+gamma*v_s[i,j])\n",
    "                    if(temp>max1):\n",
    "                        max1=temp\n",
    "                        new_policy=0\n",
    "                    if(j+1<=3):\n",
    "                        temp=1*(-1+gamma*v_s[i,j+1])\n",
    "                    else:\n",
    "                        temp=1*(-1+gamma*v_s[i,j])\n",
    "                    if(temp>max1):\n",
    "                        max1=temp\n",
    "                        new_policy=1       \n",
    "                    if(i+1<=3):\n",
    "                        temp=1*(-1+gamma*v_s[i+1,j])\n",
    "                    else:\n",
    "                        temp=1*(-1+gamma*v_s[i,j])\n",
    "                    if(temp>max1):\n",
    "                        max1=temp\n",
    "                        new_policy=2\n",
    "                    if(j-1>=0):\n",
    "                        temp=1*(-1+gamma*v_s[i,j-1])\n",
    "                    else:\n",
    "                        temp=1*(-1+gamma*v_s[i,j])\n",
    "                    if(temp>max1):\n",
    "                        max1=temp\n",
    "                        new_policy=3\n",
    "                    new_v=max1\n",
    "                v_s[i,j]=new_v\n",
    "                delta=max(delta,abs(v-new_v))\n",
    "        if(delta<theeta):\n",
    "            break\n",
    "    deterministic_policy(v_s,pi_s,gamma)\n",
    "    print(\"----value_iteartion----\")\n",
    "    print(\"Value function:\")\n",
    "    print(v_s)\n",
    "    print(\"Policy Selected:\")\n",
    "    print(pi_s)\n",
    "    print()\n",
    "                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----policy_iteartion----\n",
      "iteration No. 1 :\n",
      "Value function:\n",
      "[[ 0.         -9.99999999 -9.99999999 -9.99999999]\n",
      " [-1.         -9.99999999 -9.99999999 -9.99999999]\n",
      " [-1.9        -9.99999999 -9.99999999 -9.99999999]\n",
      " [-2.71       -9.99999999 -9.99999999  0.        ]]\n",
      "Policy Selected:\n",
      "[[0. 3. 0. 0.]\n",
      " [0. 3. 0. 0.]\n",
      " [0. 3. 0. 2.]\n",
      " [0. 3. 1. 0.]]\n",
      "\n",
      "iteration No. 2 :\n",
      "Value function:\n",
      "[[ 0.         -1.         -9.99999999 -9.99999999]\n",
      " [-1.         -1.9        -9.99999999 -9.99999999]\n",
      " [-1.9        -2.71       -9.99999999 -1.        ]\n",
      " [-2.71       -3.439      -1.          0.        ]]\n",
      "Policy Selected:\n",
      "[[0. 3. 3. 0.]\n",
      " [0. 0. 3. 2.]\n",
      " [0. 0. 1. 2.]\n",
      " [0. 1. 1. 0.]]\n",
      "\n",
      "iteration No. 3 :\n",
      "Value function:\n",
      "[[ 0.         -1.         -1.9        -9.99999999]\n",
      " [-1.         -1.9        -2.71       -1.9       ]\n",
      " [-1.9        -2.71       -1.9        -1.        ]\n",
      " [-2.71       -1.9        -1.          0.        ]]\n",
      "Policy Selected:\n",
      "[[0. 3. 3. 2.]\n",
      " [0. 0. 0. 2.]\n",
      " [0. 0. 1. 2.]\n",
      " [0. 1. 1. 0.]]\n",
      "\n",
      "iteration No. 4 :\n",
      "Value function:\n",
      "[[ 0.   -1.   -1.9  -2.71]\n",
      " [-1.   -1.9  -2.71 -1.9 ]\n",
      " [-1.9  -2.71 -1.9  -1.  ]\n",
      " [-2.71 -1.9  -1.    0.  ]]\n",
      "Policy Selected:\n",
      "[[0. 3. 3. 2.]\n",
      " [0. 0. 0. 2.]\n",
      " [0. 0. 1. 2.]\n",
      " [0. 1. 1. 0.]]\n",
      "\n",
      "----value_iteartion----\n",
      "Value function:\n",
      "[[ 0.   -1.   -1.9  -2.71]\n",
      " [-1.   -1.9  -2.71 -1.9 ]\n",
      " [-1.9  -2.71 -1.9  -1.  ]\n",
      " [-2.71 -1.9  -1.    0.  ]]\n",
      "Policy Selected:\n",
      "[[0. 3. 3. 2.]\n",
      " [0. 0. 0. 2.]\n",
      " [0. 0. 1. 2.]\n",
      " [0. 1. 1. 0.]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "policy_iteration()\n",
    "value_iteration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
